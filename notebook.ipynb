{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Introduction to ML - Decision Tree Coursework</center>\n",
    "### <center>COMP70050</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib==3.9.2 (from -r requirements.txt (line 1))\n",
      "  Downloading matplotlib-3.9.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting numpy==2.1.1 (from -r requirements.txt (line 2))\n",
      "  Downloading numpy-2.1.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scipy==1.14.1 (from -r requirements.txt (line 3))\n",
      "  Downloading scipy-1.14.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting contourpy>=1.0.1 (from matplotlib==3.9.2->-r requirements.txt (line 1))\n",
      "  Downloading contourpy-1.3.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib==3.9.2->-r requirements.txt (line 1))\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib==3.9.2->-r requirements.txt (line 1))\n",
      "  Downloading fonttools-4.54.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (163 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.7/163.7 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib==3.9.2->-r requirements.txt (line 1))\n",
      "  Downloading kiwisolver-1.4.7-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./ml_cw/lib/python3.12/site-packages (from matplotlib==3.9.2->-r requirements.txt (line 1)) (24.1)\n",
      "Collecting pillow>=8 (from matplotlib==3.9.2->-r requirements.txt (line 1))\n",
      "  Downloading pillow-11.0.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib==3.9.2->-r requirements.txt (line 1))\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./ml_cw/lib/python3.12/site-packages (from matplotlib==3.9.2->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./ml_cw/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib==3.9.2->-r requirements.txt (line 1)) (1.16.0)\n",
      "Downloading matplotlib-3.9.2-cp312-cp312-macosx_11_0_arm64.whl (7.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.1.1-cp312-cp312-macosx_14_0_arm64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.1-cp312-cp312-macosx_14_0_arm64.whl (23.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.0-cp312-cp312-macosx_11_0_arm64.whl (251 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.5/251.5 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.54.1-cp312-cp312-macosx_11_0_arm64.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.7-cp312-cp312-macosx_11_0_arm64.whl (63 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.0.0-cp312-cp312-macosx_11_0_arm64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyparsing, pillow, numpy, kiwisolver, fonttools, cycler, scipy, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.0 cycler-0.12.1 fonttools-4.54.1 kiwisolver-1.4.7 matplotlib-3.9.2 numpy-2.1.1 pillow-11.0.0 pyparsing-3.2.0 scipy-1.14.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 8)\n",
      "(2000, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "clean_data = x = np.loadtxt(\"wifi_db/clean_dataset.txt\", delimiter='\\t')\n",
    "print(clean_data.shape)\n",
    "\n",
    "noisy_data = x = np.loadtxt(\"wifi_db/noisy_dataset.txt\")\n",
    "print(noisy_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, attribute, value, left, right, is_leaf):\n",
    "        self.attribute = attribute\n",
    "        self.value = value\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.is_leaf = is_leaf\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(labels):\n",
    "    _, counts = np.unique(labels, return_counts=True)\n",
    "    prob = counts / np.sum(counts)\n",
    "    H = - np.sum(prob * np.log2(prob))\n",
    "\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_split(dataset):\n",
    "    # We split out dataset, x is the array of features and y is the labels\n",
    "    x = dataset[:, :-1]\n",
    "    y = dataset[:, -1]\n",
    "\n",
    "    # n is the number of samples and k is the number of features\n",
    "    n, k = x.shape\n",
    "\n",
    "    H_total = entropy(y)\n",
    "    max_gain = 0\n",
    "    max_gain_attribute = -1\n",
    "    max_gain_split = -1\n",
    "\n",
    "    for attribute in range(k):\n",
    "        arr = x[:, attribute]\n",
    "        uniques = np.unique(arr)\n",
    "    \n",
    "\n",
    "        for split in uniques:\n",
    "            left_ds = y[arr <= split]\n",
    "            right_ds = y[arr > split]\n",
    "\n",
    "\n",
    "\n",
    "            remainder = ((len(left_ds)/len(arr)) * entropy(left_ds)) + ((len(right_ds)/len(arr)) * entropy(right_ds))\n",
    "            if max_gain < H_total - remainder:\n",
    "\n",
    "                max_gain = H_total - remainder\n",
    "                max_gain_attribute = attribute\n",
    "                max_gain_split = split\n",
    "    \n",
    "    return max_gain_attribute, max_gain_split\n",
    "\n",
    "        # sorted_indecies = np.argsort(x[:, attribute])\n",
    "        # sorted_attribute = x[:, attribute][sorted_indecies]\n",
    "        # idx = 0\n",
    "        # for value in uniques:\n",
    "        #     current = sorted_attribute[idx]\n",
    "        #     while current == value:\n",
    "        #         idx+=1\n",
    "\n",
    "        # for split in len(1, sorted_attribute):\n",
    "        #     if sorted_attribute[split - 1] == sorted_attribute[split]:\n",
    "        #         continue\n",
    "        \n",
    "            \n",
    "        \n",
    "\n",
    "    return H_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, np.float64(-55.0))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_split(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_learning(self, dataset, depth=1):\n",
    "    x = dataset[:, :-1]\n",
    "    y = dataset[:, -1]\n",
    "    if len(np.unique(y)) == 1:\n",
    "        return (Node(None, y[0], None, None, True), depth)\n",
    "    else:\n",
    "        attribute, value = find_split(dataset)\n",
    "\n",
    "        l_dataset = dataset[dataset[attribute] <= value]\n",
    "        r_dataset = dataset[dataset[attribute]  > value]\n",
    "\n",
    "        l_branch, l_depth = decision_tree_learning(l_dataset, depth+1)\n",
    "        r_branch, r_depth = decision_tree_learning(r_dataset, depth+1)\n",
    "\n",
    "        node = Node(attribute, value, l_branch, r_branch, False)\n",
    "\n",
    "        return (node, max(l_depth, r_depth))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_cw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
