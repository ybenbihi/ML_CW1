{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Introduction to ML - Decision Tree Coursework</center>\n",
    "### <center>COMP70050</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 8)\n",
      "(2000, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "clean_data = x = np.loadtxt(\"wifi_db/clean_dataset.txt\", delimiter='\\t')\n",
    "print(clean_data.shape)\n",
    "\n",
    "noisy_data = x = np.loadtxt(\"wifi_db/noisy_dataset.txt\")\n",
    "print(noisy_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(labels):\n",
    "    _, counts = np.unique(labels, return_counts=True)\n",
    "    prob = counts / np.sum(counts)\n",
    "    H = - np.sum(prob * np.log2(prob))\n",
    "\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, attribute, value, left, right, is_leaf):\n",
    "        self.attribute = attribute\n",
    "        self.value = value\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.is_leaf = is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self):\n",
    "        self.root: Node = None\n",
    "        self.depth = 0\n",
    "\n",
    "    def find_split(self, dataset):\n",
    "        # We split out dataset, x is the array of features and y is the labels\n",
    "        x = dataset[:, :-1]\n",
    "        y = dataset[:, -1]\n",
    "\n",
    "        # n is the number of samples and k is the number of features\n",
    "        n, k = x.shape\n",
    "\n",
    "        H_total = entropy(y)\n",
    "        max_gain = 0\n",
    "        max_gain_attribute = -1\n",
    "        max_gain_split = -1\n",
    "\n",
    "        for attribute in range(k):\n",
    "            arr = x[:, attribute]\n",
    "            uniques = np.unique(arr)\n",
    "\n",
    "            for split in uniques:\n",
    "                left_ds = y[arr <= split]\n",
    "                right_ds = y[arr > split]\n",
    "\n",
    "                remainder = ((len(left_ds)/len(arr)) * entropy(left_ds)) + ((len(right_ds)/len(arr)) * entropy(right_ds))\n",
    "                if max_gain < H_total - remainder:\n",
    "\n",
    "                    max_gain = H_total - remainder\n",
    "                    max_gain_attribute = attribute\n",
    "                    max_gain_split = split\n",
    "        \n",
    "        return max_gain_attribute, max_gain_split\n",
    "\n",
    "    def decision_tree_learning(self, dataset, depth=1):\n",
    "        x = dataset[:, :-1]\n",
    "        y = dataset[:, -1]\n",
    "        if len(np.unique(y)) == 1:\n",
    "            return (Node(None, y[0], None, None, True), depth)\n",
    "        else:\n",
    "            attribute, value = self.find_split(dataset)\n",
    "\n",
    "            l_dataset = dataset[dataset[:, attribute] <= value]\n",
    "            r_dataset = dataset[dataset[:, attribute]  > value]\n",
    "\n",
    "            l_branch, l_depth = self.decision_tree_learning(l_dataset, depth + 1)\n",
    "            r_branch, r_depth = self.decision_tree_learning(r_dataset, depth + 1)\n",
    "\n",
    "            node = Node(attribute, value, l_branch, r_branch, False)\n",
    "\n",
    "            self.root = node\n",
    "            self.depth = max(l_depth, r_depth)\n",
    "            return (node, max(l_depth, r_depth))\n",
    "        \n",
    "    def predict(self, x):\n",
    "        y = np.zeros(len(x))\n",
    "        for i in range(len(y)):\n",
    "            current_node = self.root\n",
    "            while not current_node.is_leaf:\n",
    "                if x[i, current_node.attribute] <= current_node.value :\n",
    "                    current_node = current_node.left\n",
    "                else :\n",
    "                    current_node = current_node.right\n",
    "\n",
    "            y[i] = current_node.value\n",
    "\n",
    "        return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_split(dataset):\n",
    "    # We split out dataset, x is the array of features and y is the labels\n",
    "    x = dataset[:, :-1]\n",
    "    y = dataset[:, -1]\n",
    "\n",
    "    # n is the number of samples and k is the number of features\n",
    "    n, k = x.shape\n",
    "\n",
    "    H_total = entropy(y)\n",
    "    max_gain = 0\n",
    "    max_gain_attribute = -1\n",
    "    max_gain_split = -1\n",
    "\n",
    "    for attribute in range(k):\n",
    "        arr = x[:, attribute]\n",
    "        uniques = np.unique(arr)\n",
    "    \n",
    "\n",
    "        for split in uniques:\n",
    "            left_ds = y[arr <= split]\n",
    "            right_ds = y[arr > split]\n",
    "\n",
    "\n",
    "\n",
    "            remainder = ((len(left_ds)/len(arr)) * entropy(left_ds)) + ((len(right_ds)/len(arr)) * entropy(right_ds))\n",
    "            if max_gain < H_total - remainder:\n",
    "\n",
    "                max_gain = H_total - remainder\n",
    "                max_gain_attribute = attribute\n",
    "                max_gain_split = split\n",
    "    \n",
    "    return max_gain_attribute, max_gain_split\n",
    "\n",
    "        # sorted_indecies = np.argsort(x[:, attribute])\n",
    "        # sorted_attribute = x[:, attribute][sorted_indecies]\n",
    "        # idx = 0\n",
    "        # for value in uniques:\n",
    "        #     current = sorted_attribute[idx]\n",
    "        #     while current == value:\n",
    "        #         idx+=1\n",
    "\n",
    "        # for split in len(1, sorted_attribute):\n",
    "        #     if sorted_attribute[split - 1] == sorted_attribute[split]:\n",
    "        #         continue\n",
    "        \n",
    "            \n",
    "        \n",
    "\n",
    "    return H_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_learning(dataset, depth=1):\n",
    "    x = dataset[:, :-1]\n",
    "    y = dataset[:, -1]\n",
    "    if len(np.unique(y)) == 1:\n",
    "        return (Node(None, y[0], None, None, True), depth)\n",
    "    else:\n",
    "        attribute, value = find_split(dataset)\n",
    "\n",
    "        l_dataset = dataset[dataset[attribute] <= value]\n",
    "        r_dataset = dataset[dataset[attribute]  > value]\n",
    "\n",
    "        l_branch, l_depth = decision_tree_learning(l_dataset, depth+1)\n",
    "        r_branch, r_depth = decision_tree_learning(r_dataset, depth+1)\n",
    "\n",
    "        node = Node(attribute, value, l_branch, r_branch, False)\n",
    "\n",
    "        return (node, max(l_depth, r_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 : Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_gold, y_prediction, class_labels=None):\n",
    "    \"\"\" Compute the confusion matrix.\n",
    "\n",
    "    Args:\n",
    "        y_gold (np.ndarray): the correct ground truth/gold standard labels\n",
    "        y_prediction (np.ndarray): the predicted labels\n",
    "        class_labels (np.ndarray): a list of unique class labels.\n",
    "                               Defaults to the union of y_gold and y_prediction.\n",
    "\n",
    "    Returns:\n",
    "        np.array : shape (C, C), where C is the number of classes.\n",
    "                   Rows are ground truth per class, columns are predictions\n",
    "    \"\"\"\n",
    "\n",
    "    # if no class_labels are given, we obtain the set of unique class labels from\n",
    "    # the union of the ground truth annotation and the prediction\n",
    "    if not class_labels:\n",
    "        class_labels = np.unique(np.concatenate((y_gold, y_prediction)))\n",
    "\n",
    "    confusion = np.zeros((len(class_labels), len(class_labels)), dtype=np.int8)\n",
    "\n",
    "    # TODO: Complete this\n",
    "    # for each correct class (row),\n",
    "    # compute how many instances are predicted for each class (columns)\n",
    "    for i, correct_class in enumerate(class_labels):\n",
    "        for j, predicted_class in enumerate(class_labels):\n",
    "            count = np.count_nonzero(np.logical_and(y_gold == correct_class, y_prediction == predicted_class))\n",
    "            confusion[i][j] = count\n",
    "\n",
    "    return confusion\n",
    "\n",
    "def accuracy(confusion):\n",
    "    \"\"\" Compute the accuracy given the confusion matrix\n",
    "\n",
    "    Args:\n",
    "        confusion (np.ndarray): shape (C, C), where C is the number of classes.\n",
    "                    Rows are ground truth per class, columns are predictions\n",
    "\n",
    "    Returns:\n",
    "        float : the accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    if np.sum(confusion) > 0:\n",
    "        # TODO: Complete this\n",
    "        return np.trace(confusion) / np.sum(confusion)\n",
    "    else:\n",
    "        return 0.\n",
    "\n",
    "def precision(confusion):\n",
    "    \"\"\" Compute the precision score per class given the ground truth and predictions\n",
    "\n",
    "    Also return the macro-averaged precision across classes.\n",
    "\n",
    "    Args:\n",
    "        y_gold (np.ndarray): the correct ground truth/gold standard labels\n",
    "        y_prediction (np.ndarray): the predicted labels\n",
    "\n",
    "    Returns:\n",
    "        tuple: returns a tuple (precisions, macro_precision) where\n",
    "            - precisions is a np.ndarray of shape (C,), where each element is the\n",
    "              precision for class c\n",
    "            - macro-precision is macro-averaged precision (a float)\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Complete this function\n",
    "\n",
    "    # Compute the precision per class\n",
    "    p = np.diag(confusion) / np.sum(confusion, axis=1)\n",
    "\n",
    "    # Compute the macro-averaged precision\n",
    "    macro_p = np.mean(p)\n",
    "\n",
    "    return (p, macro_p)\n",
    "\n",
    "def recall(confusion):\n",
    "    \"\"\" Compute the recall score per class given the ground truth and predictions\n",
    "\n",
    "    Also return the macro-averaged recall across classes.\n",
    "\n",
    "    Args:\n",
    "        y_gold (np.ndarray): the correct ground truth/gold standard labels\n",
    "        y_prediction (np.ndarray): the predicted labels\n",
    "\n",
    "    Returns:\n",
    "        tuple: returns a tuple (recalls, macro_recall) where\n",
    "            - recalls is a np.ndarray of shape (C,), where each element is the\n",
    "                recall for class c\n",
    "            - macro-recall is macro-averaged recall (a float)\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Complete this function\n",
    "\n",
    "    # Compute the recall per class\n",
    "    r = np.diag(confusion) / np.sum(confusion, axis=0)\n",
    "\n",
    "    # Compute the macro-averaged recall\n",
    "    macro_r = np.mean(r)\n",
    "\n",
    "    return (r, macro_r)\n",
    "\n",
    "def f1_score(confusion):\n",
    "    \"\"\" Compute the F1-score per class given the ground truth and predictions\n",
    "\n",
    "    Also return the macro-averaged F1-score across classes.\n",
    "\n",
    "    Args:\n",
    "        y_gold (np.ndarray): the correct ground truth/gold standard labels\n",
    "        y_prediction (np.ndarray): the predicted labels\n",
    "\n",
    "    Returns:\n",
    "        tuple: returns a tuple (f1s, macro_f1) where\n",
    "            - f1s is a np.ndarray of shape (C,), where each element is the\n",
    "              f1-score for class c\n",
    "            - macro-f1 is macro-averaged f1-score (a float)\n",
    "    \"\"\"\n",
    "\n",
    "    (precisions, macro_p) = precision(confusion)\n",
    "    (recalls, macro_r) = recall(confusion)\n",
    "\n",
    "    # just to make sure they are of the same length\n",
    "    assert len(precisions) == len(recalls)\n",
    "\n",
    "    # TODO: Complete this to compute the per-class F1\n",
    "    f = (2*precisions*recalls) / (precisions + recalls)\n",
    "\n",
    "    # TODO: Compute the macro-averaged F1\n",
    "    macro_f = np.mean(f)\n",
    "\n",
    "    return (f, macro_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Lab 3\n",
    "def k_fold_split(n_splits, n_instances, random_generator=np.random.default_rng()):\n",
    "    \"\"\" Split n_instances into n mutually exclusive splits at random.\n",
    "\n",
    "    Args:\n",
    "        n_splits (int): Number of splits\n",
    "        n_instances (int): Number of instances to split\n",
    "        random_generator (np.random.Generator): A random generator\n",
    "\n",
    "    Returns:\n",
    "        list: a list (length n_splits). Each element in the list should contain a\n",
    "            numpy array giving the indices of the instances in that split.\n",
    "    \"\"\"\n",
    "\n",
    "    # generate a random permutation of indices from 0 to n_instances\n",
    "    shuffled_indices = random_generator.permutation(n_instances)\n",
    "\n",
    "    # split shuffled indices into almost equal sized splits\n",
    "    split_indices = np.array_split(shuffled_indices, n_splits)\n",
    "\n",
    "    return split_indices\n",
    "\n",
    "def train_test_k_fold(n_folds, n_instances, random_generator=np.random.default_rng()):\n",
    "    \"\"\" Generate train and test indices at each fold.\n",
    "\n",
    "    Args:\n",
    "        n_folds (int): Number of folds\n",
    "        n_instances (int): Total number of instances\n",
    "        random_generator (np.random.Generator): A random generator\n",
    "\n",
    "    Returns:\n",
    "        list: a list of length n_folds. Each element in the list is a list (or tuple)\n",
    "            with two elements: a numpy array containing the train indices, and another\n",
    "            numpy array containing the test indices.\n",
    "    \"\"\"\n",
    "\n",
    "    # split the dataset into k splits\n",
    "    split_indices = k_fold_split(n_folds, n_instances, random_generator)\n",
    "\n",
    "    folds = []\n",
    "    for k in range(n_folds):\n",
    "        test_indices = split_indices[k]\n",
    "        train_indices = np.concatenate(split_indices[:k] + split_indices[k+1:])\n",
    "\n",
    "        folds.append([train_indices, test_indices])\n",
    "\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9710000000000001\n",
      "0.9712722451857989\n",
      "0.9710197756661246\n",
      "0.970741418018506\n",
      "[[47.  0.  0.  0.]\n",
      " [ 0. 59.  5.  0.]\n",
      " [ 1.  2. 38.  0.]\n",
      " [ 0.  0.  0. 48.]]\n"
     ]
    }
   ],
   "source": [
    "dataset = clean_data\n",
    "n_folds = 10\n",
    "n_instances = len(dataset)\n",
    "\n",
    "confusion_matrices = np.zeros((n_folds, 4, 4))\n",
    "accuracies = np.zeros(n_folds)\n",
    "precisions = np.zeros(n_folds)\n",
    "recalls = np.zeros(n_folds)\n",
    "f1_scores = np.zeros(n_folds)\n",
    "\n",
    "for i, (train_indices, test_indices) in enumerate(train_test_k_fold(n_folds, len(x))):\n",
    "    # Splitting the train and test\n",
    "    x_train = dataset[train_indices, :-1]\n",
    "    y_train = dataset[train_indices, -1]\n",
    "    x_test = dataset[test_indices, :-1]\n",
    "    y_test = dataset[test_indices, -1]\n",
    "\n",
    "    model = DecisionTree()\n",
    "    model.decision_tree_learning(dataset[train_indices])\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    confusion_matrices[i] = confusion_matrix(np.int8(y_test), np.int8(y_pred))\n",
    "    accuracies[i] = accuracy(confusion_matrices[i])\n",
    "    precisions[i] = precision(confusion_matrices[i])[1]\n",
    "    recalls[i] = recall(confusion_matrices[i])[1]\n",
    "    f1_scores[i] = f1_score(confusion_matrices[i])[1]\n",
    "\n",
    "print(accuracies.mean())\n",
    "print(precisions.mean())\n",
    "print(recalls.mean())\n",
    "print(f1_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_cw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
